# Java性能调优工具箱

## 操作系统的工具和分析

### CPU使用率

### CPU运行队列

### 磁盘使用率

### 网络使用率

## Java监控工具

* jcmd 它用来打印Java进程所涉及的基本类、线程和VM信息。

  ```bash
  jcmd process_id command optional_arguments
  ```

* jconsol 提供JVM活动的图形化视图，包括线程的使用、类的使用和GC活动。

* jhat 提供JVM活动的图形化视图，包括线程的使用、类的使用和GC活动。

* jmap 提供堆转储和其他JVM内存使用的信息。可以适用于脚本，但堆转储必须在事后分析工具中使用。

* jinfo 查看JVM的系统属性，可以动态设置一些系统属性。可适用于脚本。

* jstack 转储Java进程的栈信息。可适用于脚本。

* jstat 提供GC和类装载活动的信息。可适用于脚本。

* jvisualvm 监视JVM的GUI工具，可用来剖析运行的应用，分析JVM堆转储（事后活动，虽然jvisualvm也可以实时抓取程序的堆转储）。

### 基本的VM信息

```bash
jcmd process_id VM.uptime 									# JVM运行时长
jcmd process_id VM.system_properties    		# 系统属性
jinfo -sysprops process_id 									# 系统属性 等同于上一条
jcmd process_id VM.version									# 获取JVM版本
jcmd process_id VM.command_line 						# 显示程序所用的命令行
jcmd process_id VM.flags 										# 生效的JVM调优标志
java -XX:+PrintFlagsFinal -version					# 输出所有的调优标志
jinfo -flag -PrintGCDetails process_id			# turns off PrintGCDetails
```

### 线程信息

```bash
jstack process_id 
jcmd process_id Thread.print
```

## 性能分析工具

### 采样分析器

性能分析有两种模式

* 数据采样
* 数据探查

## Java任务控制



# JIT 编译器

## 概览

### 热点编译

## 调优入门：选择编译器类型（Client、Server或者二者同用）

## 编译器中级调优

### 调优代码缓存

* XX:ReservedCodeCacheSize=N 设置代码缓存的最大值


1. 代码缓存是一种有最大值的资源，它会影响JVM可运行的编译代码总量
2. 分层编译很容易达到代码缓默认配置的上线。

### 编译阈值

1. 当方法和循环执行次数达到某个阈值的时候，就会发生编译。
2. 改变阈值会导致代码提早或推后编译。
3. 由于计数器会随着时间而减少，以至于“温热”的方法可能永远都达不到编译的阈值（特别是对server编译器来说）。

### 检测编译过程

## 高级编译器调优

### 编译线程

1. 放置在编译队列中的方法的编译会被异步执行
2. 队列并不是严格按照先后顺序的；队列中的热点方法会在其他方法之前编译。

### 内联

内联默认时开启的。可通过`-XX:-Inline`关闭。 `-XX:PrintInlining`这个参数提供所有关于编译器如何进行内联决策的信息。

1. 内联是编译器所能做的最有利的优化，特别是对属性封装良好的面向对象的代码来说。
2. 几乎用不着调节内联参数，且提倡这样做的建议往往忽略了常规内联和频繁调用内联之间的关系。

### 逃逸分析

开启逃逸分析 `-XX:+DoEscapeAnalysis`, 默认true

1. 逃逸分析是编译器能做得最复杂的优化。此类优化常常会导致微基准测试失败。
2. 逃逸分析常常会给不正确的同步代码引入“bug”

## 逆优化

1. 逆优化使得编译器可以回到之前版本的编译代码。
2. 先前的优化不再有效时（例如，所涉及的对象类型发生了改变），才会发生代码逆优化
3. 代码逆优化时，会对性能产生一些小而短暂的影响，不过新编译的代码会尽快地再次热身。
4. 分层编译时，如果代码之前由client编译器编译而现在由server编译器优化，就会发生逆优化。


## 分层编译级别

1. 分层编译可以在两种编译器和5种级别之间进行。
2. 不建议人为更改级别，本节仅仅是辅助解释编译日志的输出。

# 垃圾收集入门

## 垃圾收集概述

垃圾收集由两步构成：查找不再使用的对象，以及释放这些对象所管理的内存。

**时空停顿（stop-the-world）** 所有线程都停止运行所产生的停顿

### 分代垃圾收集器

所有的垃圾收集器都遵循了同一个方式，即根据情况将堆划分成不同的代（Generation）。这些代被称为 **老年代（Old Generation 或 Tenured Generation）**和 **新生代（Young Generation）**。新生代又进一步被划分为不同的区段，分别称为**Eden空间**和**Survivor空间**

1. 所有的GC算法都将堆划分成了老年代和新生代。
2. 所有的GC算法在清理新生代对象时，都使用了“时空停顿”（stoptheworld）方式的垃圾收集方法，通常这是一个能较快完成的操作。

### GC算法

#### Serial垃圾收集器 

使用单线程清理堆的内容。

#### Throughput垃圾收集器

Throughput收集器使用多线程回收新生代空间，MinorGC的速度比使用Serial收集器快得多。处理老年代时Throughput收集器也能使用多线程方式。这已经是JDK7u4及之后的版本的默认行为，对于之前老版本的JDK7虚拟机，通过XX:+UseParallelOldGC标志可以开启这个功能。

#### CMS收集器

CMS收集器设计的初衷是为了消除Throughput收集器和Serial收集器FullGC周期中的长时间停顿。CMS收集器在MinorGC时会暂停所有的应用线程，并以多线程的方式进行垃圾回收。然而，这其中最显著的不同是，CMS不再使用Throughput的收集算法（XX:+UseParallelGC），改用新的算法来收集新生代对象（使用XX:+UseParNewGC标志）。

CMS收集器在FullGC时不再暂停应用线程，而是使用若干个后台线程定期地对老年代空间进行扫描，及时回收其中不再使用的对象。这种算法帮助CMS成为一个低延迟的收集器：应用线程只在MinorGC以及后台线程扫描老年代时发生极其短暂的停顿。应用程序线程停顿的总时长与使用Throughput收集器比起来短得多。

#### G1垃圾收集器

G1垃圾收集器（或者垃圾优先收集器）的设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。G1收集算法将堆划分为若干个区域（Region），不过它依旧属于分代收集器。这些区域中的一部分包含新生代，新生代的垃圾收集仍然采用暂停所有应用线程的方式，将存活对象移动到老年代或者Survivor空间。同其他的收集算法一样，这些操作也利用多线程的方式完成。



1. 这四种垃圾收集算法分别采用了的不同的方法来缓解GC对应用程序的影响。

2. Serial收集器常用于仅有单CPU可用以及当其他程序会干扰GC的情况（通常是默认值）。
3. Throughput收集器在其他的虚拟机上是默认值，它能最大化应用程序的总吞吐量，但是有些操作可能遭遇较长的停顿。
4. CMS收集器能够在应用线程运行的同时并行地对老年代的垃圾进行收集。如果CPU的计算能力足以支撑后台垃圾收集线程的运行，该算法能避免应用程序发生FullGC。5.G1收集器也能在应用线程运行的同时并发地对老年代的垃圾进行收集，在某种程度上能够减少发生FullGC的风险。G1的设计理念使得它比CMS更不容易遭遇FullGC。

### 选择GC算法

### GC算法和吞吐量测试

### GC算法及响应时间测试

### CMS收集器和G1收集器之间的抉择

1. 选择Concurrent收集器时，如果堆较小，推荐使用CMS收集器。
2. G1的设计使得它能够在不同的分区（Region）处理堆，因此它的扩展性更好，比CMS更易于处理超大堆的情况。

## GC调优基础

### 调整堆的大小

堆的大小由2个参数值控制：初始值 `-Xms N`和最大值`-Xmx N`

1. JVM会根据其运行的机器，尝试估算合适的最大、最小堆的大小。

2. 除非应用程序需要比默认值更大的堆，否则在进行调优时，尽量考虑通过调整GC算法的性能目标（具体内容在下一章介绍），而非微调堆的大小来改善程序性能。

### 代空间的调整

* `-XX:NewRatio=N` 设置新生代与老年代的空间占用比率。
* `-XX:NewSize=N` 设置新生代空间的初始大小。
* `-XX:MaxNewSize=N` 设置新生代空间的最大大小。
* `-XmnN` 将`NewSize`和`MaxNewSize`设定为同一个值的快捷方法。

1. 整个堆范围内，不同代的大小划分是由新生代所占用的空间控制的。
2. 新生代的大小会随着整个堆大小的增大而增长，但这也是随着整个堆的空间比率波动变化的（依据新生代的初始值和最大值）。

### 永久代和元空间的调整

1. 永久代或元空间保存着类的元数据（并非类本体的数据）。它以分离的堆的形式存在。
2. 典型应用程序在启动后不需要载入新的类，这个区域的初始值可以依据所有类都加载后的情况设置。使用优化的初始值能够加速启动的过程。
3. 开发中的应用服务器（或者任何需要频繁重新载入类的环境）上经常能碰到由于永久代或元空间耗尽触发的FullGC，这时老的元数据会被丢弃回收。

### 控制并发

由于GC操作会暂停所有的应用程序线程，JVM为了尽量缩短停顿时间就必须尽可能地利用更多的CPU资源。JVM会在机器的每个CPU上运行一个线程，最多同时运行8个。一旦达到这个上限，JVM会调整算法，每超出5/8个CPU启动一个新的线程。


$$
ParallelGCThreads = 8 + ((N - 8) * 5 / 8)
$$

1. 几乎所有的垃圾收集算法中基本的垃圾回收线程数都依据机器上的CPU数目计算得出。
2. 多个JVM运行于同一台物理机上时，依据公式计算出的线程数可能过高，必须进行优化（减少）。

### 自适应调整

1. JVM在堆的内部如何调整新生代及老年代的百分比是由自适应调整机制控制的。
2. 通常情况下，我们应该开启自适应调整，因为垃圾回收算法依赖于调整后的代的大小来达到它停顿时间的性能目标。
3. 对于已经精细调优过的堆，关闭自适应调整能获得一定的性能提升。

## 垃圾回收工具

`-verbose:gc`或`-XX:PrintGC`这两个标志中的任意一个能创建基本GC日志

`-XX:+PrintGCDetails` 输出更详细GC日志

`XX:+PrintGCTimeStamps`或者`-XX:+PrintGCDateStamps` 判断几次GC操作之间的时间。

1. GC日志是分析GC相关问题的重要线索；我们应该开启GC日志标志（即使是在生产服务器上）。
2. 使用PrintGCDetails标志能获得更详尽的GC日志信息。
3. 使用工具能很有效地帮助我们解析和理解GC日志的内容，尤其是在对GC日志中的数据进行归纳汇总时，它们非常有帮助。
4. 使用jstat能动态地观察运行程序的垃圾回收操作。

```bash
jstat -gcutil process_id 1000    # 打印垃圾收集的信息
```



# 垃圾收集算法

## 理解Throughput收集器

* 回收新生代的垃圾
* 回收老年代的垃圾

## 理解CMS收集器

* CMS收集器会对新生代的对象进行回收（所有的应用线程都会被暂停）；
* CMS收集器会启动一个并发的线程对老年代空间的垃圾进行回收；
* 如果有必要，CMS会发起FullGC

1. CMS垃圾回收有多个操作，但是期望的操作是MinorGC和并发回收（concurrentcycle）。
2. CMS收集过程中的并发模式失效以及晋升失败的代价都非常昂贵；我们应该尽量调优CMS收集器以避免发生这些情况。
3. 默认情况下CMS收集器不会对永久代进行垃圾回收。

### 针对并发模式失效的调优

当老年代空间的占用达到某个程度（默认值为70%）时，并发回收就开始了。一个CMS后台线程开始扫描老年代空间，寻找无用的垃圾对象时，竞争就开始了：CMS收集器必须在老年代剩余的空间（30%）用尽之前，完成老年代空间的扫描及回收工作。如果并发回收在这场速度的比赛中失利，CMS收集器就会发生并发模式失效。

解决方案

* 想办法增大老年代空间，要么只移动部分的新生代对象到老年代，要么增加更多的堆空间。

* 以更高的频率运行后台回收线程。

* 使用更多的后台回收线程。

1. 给后台线程更多的运行机会
2. 调整CMS后台线程

1. 避免发生并发模式失效是提升CMS收集器处理能力、获得高性能的关键。
2. 避免并发模式失效（如果有可能的话）最简单的方法是增大堆的容量。
3. 否则，我们能进行的下一个步骤就是通过调整CMSInitiatingOccupancyFraction参数，尽早启动并发后台线程的运行。
4. 另外，调整后台线程的数目对解决这个问题也有帮助。

### CMS收集器的永久代调优

### 增量式CMS垃圾收集

java8中已经不推荐

## 理解G1垃圾收集器

G1垃圾收集器是一种工作在堆内不同分区上的并发收集器。分区（region）既可以归属于老年代，也可以归属于新生代（默认情况下，一个堆被划分成2048个分区），同一个代的分区不需要保持连续。

G1收集器的收集活动主要包括4种操作：

* 新生代垃圾收集；
* 后台收集，并发周期；
* 混合式垃圾收集；
* 以及必要时的FullGC。

1. G1垃圾收集包括多个周期（以及并发周期内的阶段）。调优良好的JVM运行G1收集器时应该只经历新生代周期、混合式周期和并发GC周期。
2. G1的并发阶段会产生少量的停顿。
3. 恰当的时候，我们需要对G1进行调优，才能避免FullGC周期发生。

### G1垃圾收集器调优

避免发生FullGC

* 通过增加总的堆空间大小或者调整老年代、新生代之间的比例来增加老年代空间的大小。
* 增加后台线程的数目（假设我们有足够的CPU资源运行这些线程）。
* 以更高的频率进行G1的后台垃圾收集活动。
* 在混合式垃圾回收周期中完成更多的垃圾收集工作。

如果无法避免FullGC

1. 调整G1垃圾收集的后台线程数
2. 调整G1垃圾收集器的运行频率
3. 调整G1收集器的混合式垃圾收集周期

1. 作为G1收集器调优的第一步，首先应该设定一个合理的停顿时间作为目标。
2. 如果使用这个设置后，还是频繁发生FullGC，并且堆的大小没有扩大的可能，这时就需要针对特定的失败采用特定的方法进行调优。　
   1. 通过InitiatingHeapOccupancyPercent标志可以调整G1收集器，更频繁地启动后台垃圾收集线程。
   2. 如果有充足的CPU资源，可以考虑调整ConcGCThreads标志，增加垃圾收集线程数。　
   3. 减小G1MixedGCCountTarget参数可以避免晋升失败。

## 高级调优

### 晋升及Survivor空间

1. 设计Survivor空间的初衷是为了让对象（尤其是已经分配的对象）在新生代停留更多的GC周期。这个设计增大了对象晋升到老年代之前被回收释放的几率。
2. 如果Survivor空间过小，对象会直接晋升到老年代，从而触发更多的老年代GC。
3. 解决这个问题的最好方法是增大堆的大小（或者至少增大新生代），让JVM来处理Survivor空间的回收。
4. 有的情况下，我们需要避免对象晋升到老年代，调整晋升阈值或者Survivor空间的大小可以避免对象晋升到老年代。

### 分配打对象

对需要分配大量大型对象的应用，TLAB空间的调整就变得必不可少（不过，通常情况下，我们更推荐在应用程序中使用小型对象的做法）。

1. G1分区的大小是2的幂，最小值为1MB。
2. 如果堆的初始大小跟最大值相差很大，这种堆会有大量的G1分区，在这种情况下，应该增大G1分区的大小。

3. 如果要分配的对象大小超过了G1收集器分区容量的一半，对于这种应用程序，我们应该增大G1分区的容量，让G1分区能更好地适配这些对象。遵循这个原则，应用程序分配对象的大小至少应是512KB（因为G1分区的最小值为1MB）。

### AggressiveHeap标志

1. AggressiveHeap是个历史悠久的调优标志，设计初衷是为了在强大的机器上运行单一JVM时调整堆的各种参数。
2. 这个标志设定的值并没有随着JVM技术的发展同步调整，因此它的有效性从长远来看是值得质疑的（虽然到目前为止，这个标志还常常被使用）。

### 全盘掌控堆空间的大小

1. 大多数的机器上堆的初始空间和最大空间的默认值计算是比较直观的。
2. 达到堆大小的临界情况时，需要考虑的因素更多，计算也更加复杂。



# 堆内存最佳实践

## 堆分析

### 堆直方图

### 堆转储

1. 了解哪些对象正在消耗内存，是了解要优化代码中哪些对象的第一步。
2. 对于识别由创建了太多某一特定类型对象所引发的内存问题，直方图这一方法快速且方便。
3. 堆转储分析是追踪内存使用的最强大的技术，不过要利用好，则需要一些耐心和努力。

### 内存溢出错误

JVM会抛出内存溢出错误（OutOfMemoryError）

* JVM没有原生内存可用；
* 永久代（在Java7和更早的版本中）或元空间（在Java8中）内存不足
* Java堆本身内存不足——对于给定的堆空间而言，应用中活跃对象太多；
* JVM执行GC耗时太多。

1. 有多种原因会导致抛出OutOfMemoryError，因此不要假设堆空间就是问题所在。
2. 对于永久代和普通的堆，内存泄漏是出现OutOfMemoryError的最常见原因；堆分析工具可以帮助我们找到泄漏的根源。

## 减少内存使用

### 减少对象大小

| 类型      | 大小                                                         |
| --------- | ------------------------------------------------------------ |
| byte      | 1                                                            |
| char      | 2                                                            |
| short     | 2                                                            |
| int       | 4                                                            |
| float     | 4                                                            |
| long      | 8                                                            |
| double    | 8                                                            |
| reference | 在32位JVM以及堆小于32GB的64位JVM上是4；在启用大堆的64位JVM上是8a |

1. 减小对象大小往往可以改进GC效率。

2. 对象大小未必总能很明显地看出来：对象会被填充到8字节的边界，对象引用的大小在32位和64位JVM上也有所不同。
3. 对象内部即使为null的实例变量也会占用空间。

### 延迟初始化

1. 只有当常用的代码路径不会初始化某个变量时，才去考虑延迟初始化该变量。
2.  一般不会在线程安全的代码上引入延迟初始化，否则会加重现有的同步成本。
3. 对于使用了线程安全对象的代码，如果要采用延迟初始化，应该使用双重检查锁。

### 不可变对象和标准划对象

1. 不可变对象为标准化（canonicalization）这种特殊的生命周期管理提供了可能性。

2. 通过标准化去掉不可变对象的冗余副本，可以极大减少应用消耗的堆内存。

### 字符串的保留

1. 如果应用中有大量字符串是一样的，那通过保留实现字符串重用收效很大。

2. 要保留很多字符串的应用可能需要调整字符串保留表的大小（除非是运行在Java7u40及更新的64位服务器JVM上）。

## 对象生命周期管理

### 对象重用

实现方式

1. 对象池
2. 局部变量

1. 对象重用通常是一种通用操作，我们并不鼓励使用它。但是这种技术可能适合初始化成本高昂，而且数量比较少的一组对象。

2. 在使用对象池还是使用线程局部变量这两种技术之间，应该有所取舍。一般而言，建设线程和可重用对象直接存在一一对应关系，则线程局部变量更容易使用。

### 弱引用、软引用与其他引用

#### 软引用

如果问题中的对象以后有很大的机会重用，可以使用软引用，但是如果该对象近期一直没有使用到（计算时也会考虑堆还有多少内存可用），垃圾收集器会回收它。软引用本质上是一个比较大的、最近最久未用（LRU）的对象池。获得较好性能的关键是确保它们会被及时清理。

#### 弱引用

当问题中的所引对象会同时被几个线程使用时，应该考虑弱引用。否则，弱引用很可能会被垃圾收集器回收：只有弱引用的对象在每个GC周期都可以回收。

#### 终结器（Finalizer）和最终引用（FinalReference）

终结器队列是一个引用队列，用于当所引对象可以被GC回收时处理Finalizer引用。

1. 非确定引用（包括软引用、弱引用、虚引用和最终引用）会改变Java对象正常的生命周期，与池或线程局部变量相比，它可以以对GC更为友好的方式实现对象重用。
2. 当应用对某个对象感兴趣，而且该对象在应用中的其他地方有强引用时，才应该使用弱引用。
3. 软引用保存可能长期存在的对象，提供了一个简单的、对GC友好的LRU缓存。
4. 非确定引用自身会消耗内存，而且会长时间抓住其他对象的内存；应该谨慎使用。



# 原生内存最佳实践

## 内存占用

在JVM使用的内存中，通常堆消耗的部分最多，但是JVM也会为内部操作分配一些内存。这类非堆内存就是原生内存。应用中也可以分配原生内存（通过JNI调用malloc()和类似方法，或者是使用NewI/O，即NIO时）。JVM使用的原生内存和堆内存的总量，就是一个应用总的内存占用（Footprint）。

### 测量内存占用

### 内存占用最小化

### 原生NIO缓冲区

开发者可以通过JNI调用来分配原生内存，但是如果NIO字节缓冲区是通过allocateDirect()方法创建的，则也会分配原生内存。从性能的角度看，原生字节缓冲区非常重要，因为它们支持原生代码和Java代码在不复制的情况下共享数据。最常见的例子是用于文件系统和套接字（socket）操作的缓冲区。把数据写入一个原生NIO缓冲区，然后再发送给通道（channel，比如文件或套接字），不需要在JVM和用于传输数据的C库之间复制数据。如果使用的是堆字节缓冲区，JVM则必须复制该缓冲区的内容。

1. JVM总的内存占用对性能影响很大，特别是当机器上的物理内存有限时。在做性能测试时，内存占用通常应该是要监控的一个方面。

2. 从调优角度看，要控制JVM的内存占用，可以限制用于直接字节缓冲区、线程栈和代码缓存的原生内存（以及堆）的使用量。

### 原生内存跟踪

`-XX:NativeMemoryTracking=off|summary|detail` 原生内存分配跟踪

`-XX:+PrintNMTStatistics` 在程序退出时打印原生内存分配信息

1. 在Java8中，原生内存跟踪（NMT）提供了JVM所使用的原生内存的详细信息。从操作系统的角度看，其中包含JVM堆（对OS而言，堆也是原生内存的一部分）。

2. 对大多数分析而言，NMT的概要模式足够了。它支持我们确定JVM提交了多少内存（以及这些内存用于干什么了）。

## 针对不同操作系统优化JVM

### 大页

#### Linux大页

```bash
grep Hugepagesize /proc/meminfo  # 内核支持哪些大页大小
echo 2200 > /proc/sys/vm/nr_hugepages  # 将这个值写到操作系统
sys.nr_hugepages     # /etc/sysctl.conf 保存值到配置文件，重启也保留
# /etc/security/limits.conf 配置用户的内存页数设置
appuser soft memlock 6513734400
appuser hard memlock 6513734400
```

#### Linux透明大页

Linux内核从2.6.32版本开始支持透明大页，这种机制不再需要上述配置。不过仍然需要为Java开启透明大页，这可以通过修改/sys/kernel/mm/transparent_hugepage/enabled来实现

1. 使用大页通常可以明显提升应用的速度。
2. 在大多数操作系统上，必须显式开启大页支持。

### 压缩oop(ordinary object pointer)

1. 压缩的oop会在最有用的时候默认开启。

2. 使用了压缩oop的31GB的堆，与稍微大一些、但因为堆太大而无法使用压缩oop的堆相比，性能通常要好一些。

# 线程与同步的性能

## 线程池与ThreadPoolExecutor

所有线程池的工作方式本质是一样的：有一个队列，任务被提交到这个队列中。（可以有不止一个队列，概念是一样的。）一定数量的线程会从该队列中取任务，然后执行。

线程池的一般行为是这样的：创建时准备好最小数目的线程，如果来了一个任务，而此时所有的线程都在忙碌，则启动一个新线程（一直到达到最大线程数），任务就可以立即执行了。否则，任务被加入等待队列，如果任务队列中已经无法加入新任务，则拒绝之。

### 设置最大线程数

### 设置最小线程数

### 线程池任务大小

### 设置ThreadPoolExecutor的大小



1. 有时对象池也是不错的选择，线程池就是情形之一：线程初始化的成本很高，线程池使得系统上的线程数容易控制。
2. 线程池必须仔细调优。盲目向池中添加新线程，在某些情况下对性能会有不利影响。
3. 在使用ThreadPoolExecutor时，选择更简单的选项通常会带来最好的、最能预见的性能。

## ForkJoinPool

1. ForkJoinPool类应该用于递归、分治算法。
2. 应该花些心思来确定，算法中的递归任务何时结束最为合适。创建太多任务会降低性能，但如果任务太少，而任务所需的执行时间又长短不一，也会降低性能。
3. Java8中使用了自动并行化的特性会用到一个公共的ForkJoinPool实例。我们可能需要根据实际情况调整这个实例的默认大小。

## 线程同步

### 同步的代价

同步代码对性能有两个方面的影响。

1. 应用在同步块上所花的时间会影响该应用的可伸缩性。
2. 获取同步锁需要一些CPU周期，所以也会影响性能。

#### 同步与可伸缩性

加速比（Speedup）可以用如下等式定义（即Amdahl定律）：

$$
Speedup = \frac{1}{(1-P)+\frac{P}{N}}
$$

P是程序并行运行部分所花的时间的比例，N是所用到的线程数（假定每个线程总有CPU可用）。所以，如果20%的代码是串行执行的（这意味着P是80%），有8个CPU可用，则可以预计存在并发的情况下加速比为3.33。

#### 锁定对象的开销

**CAS** 当存在竞争时，开销是无法预测的。CAS原语基于一种乐观的策略：线程设置某个值，执行一些代码，然后确保初始值没有被修改。如果值被修改了，那么基于CAS的代码必须再次执行这些代码。在最坏的情况下，如果有两个线程，它们都在修改CAS所保护的值，那么相互就会看到另一个线程同时也在修改这个值，就有可能会陷入无限循环。不过在实践中，两个线程不会进入这样的无限循环，但是随着竞争CAS所保护值的线程数的增加，重试次数也会增加。（如果此处的操作是只读的，那基于CAS的保护不会受竞争访问的影响。比如，不管有多少线程，它们都可以同时在同一个对象上调用AtomicLong.get()方法，而不用因竞争付出任何代价。这是使用基于CAS的设施的另一个重要优势。）

1. 线程同步有两个性能方面的代价：限制了应用的可伸缩性，以及获取锁是有开销的。
2. 同步的内存语义、基于CAS的设施和volatile关键字对性能可能会有很大的影响，特别是在有很多寄存器的大型机上。

### 避免同步

如果同步可以完全避免，那加锁的损失就不会影响应用的性能。一般的应对方式

1. 在每个线程中使用不同的对象

   使用ThreadLocal对象，在每个线程中保存一个不同的对象

2. 基于CAS的替代方案



#### volatile

考虑使用volatile变量来减少同步，进而减少其应用中的竞争。结果是，对volatile变量的同步写会非常缓慢。















