# Java性能调优工具箱

## 操作系统的工具和分析

### CPU使用率

### CPU运行队列

### 磁盘使用率

### 网络使用率

## Java监控工具

* jcmd 它用来打印Java进程所涉及的基本类、线程和VM信息。

  ```bash
  jcmd process_id command optional_arguments
  ```

* jconsol 提供JVM活动的图形化视图，包括线程的使用、类的使用和GC活动。

* jhat 提供JVM活动的图形化视图，包括线程的使用、类的使用和GC活动。

* jmap 提供堆转储和其他JVM内存使用的信息。可以适用于脚本，但堆转储必须在事后分析工具中使用。

* jinfo 查看JVM的系统属性，可以动态设置一些系统属性。可适用于脚本。

* jstack 转储Java进程的栈信息。可适用于脚本。

* jstat 提供GC和类装载活动的信息。可适用于脚本。

* jvisualvm 监视JVM的GUI工具，可用来剖析运行的应用，分析JVM堆转储（事后活动，虽然jvisualvm也可以实时抓取程序的堆转储）。

### 基本的VM信息

```bash
jcmd process_id VM.uptime 									# JVM运行时长
jcmd process_id VM.system_properties    		# 系统属性
jinfo -sysprops process_id 									# 系统属性 等同于上一条
jcmd process_id VM.version									# 获取JVM版本
jcmd process_id VM.command_line 						# 显示程序所用的命令行
jcmd process_id VM.flags 										# 生效的JVM调优标志
java -XX:+PrintFlagsFinal -version					# 输出所有的调优标志
jinfo -flag -PrintGCDetails process_id			# turns off PrintGCDetails
```

### 线程信息

```bash
jstack process_id 
jcmd process_id Thread.print
```

## 性能分析工具

### 采样分析器

性能分析有两种模式

* 数据采样
* 数据探查

## Java任务控制



# JIT 编译器

## 概览

### 热点编译

## 调优入门：选择编译器类型（Client、Server或者二者同用）

## 编译器中级调优

### 调优代码缓存

* XX:ReservedCodeCacheSize=N 设置代码缓存的最大值


1. 代码缓存是一种有最大值的资源，它会影响JVM可运行的编译代码总量
2. 分层编译很容易达到代码缓默认配置的上线。

### 编译阈值

1. 当方法和循环执行次数达到某个阈值的时候，就会发生编译。
2. 改变阈值会导致代码提早或推后编译。
3. 由于计数器会随着时间而减少，以至于“温热”的方法可能永远都达不到编译的阈值（特别是对server编译器来说）。

### 检测编译过程

## 高级编译器调优

### 编译线程

1. 放置在编译队列中的方法的编译会被异步执行
2. 队列并不是严格按照先后顺序的；队列中的热点方法会在其他方法之前编译。

### 内联

内联默认时开启的。可通过`-XX:-Inline`关闭。 `-XX:PrintInlining`这个参数提供所有关于编译器如何进行内联决策的信息。

1. 内联是编译器所能做的最有利的优化，特别是对属性封装良好的面向对象的代码来说。
2. 几乎用不着调节内联参数，且提倡这样做的建议往往忽略了常规内联和频繁调用内联之间的关系。

### 逃逸分析

开启逃逸分析 `-XX:+DoEscapeAnalysis`, 默认true

1. 逃逸分析是编译器能做得最复杂的优化。此类优化常常会导致微基准测试失败。
2. 逃逸分析常常会给不正确的同步代码引入“bug”

## 逆优化

1. 逆优化使得编译器可以回到之前版本的编译代码。
2. 先前的优化不再有效时（例如，所涉及的对象类型发生了改变），才会发生代码逆优化
3. 代码逆优化时，会对性能产生一些小而短暂的影响，不过新编译的代码会尽快地再次热身。
4. 分层编译时，如果代码之前由client编译器编译而现在由server编译器优化，就会发生逆优化。


## 分层编译级别

1. 分层编译可以在两种编译器和5种级别之间进行。
2. 不建议人为更改级别，本节仅仅是辅助解释编译日志的输出。

# 垃圾收集入门

## 垃圾收集概述

垃圾收集由两步构成：查找不再使用的对象，以及释放这些对象所管理的内存。

**时空停顿（stop-the-world）** 所有线程都停止运行所产生的停顿

### 分代垃圾收集器

所有的垃圾收集器都遵循了同一个方式，即根据情况将堆划分成不同的代（Generation）。这些代被称为 **老年代（Old Generation 或 Tenured Generation）**和 **新生代（Young Generation）**。新生代又进一步被划分为不同的区段，分别称为**Eden空间**和**Survivor空间**

1. 所有的GC算法都将堆划分成了老年代和新生代。
2. 所有的GC算法在清理新生代对象时，都使用了“时空停顿”（stoptheworld）方式的垃圾收集方法，通常这是一个能较快完成的操作。

### GC算法

#### Serial垃圾收集器 

使用单线程清理堆的内容。

#### Throughput垃圾收集器

Throughput收集器使用多线程回收新生代空间，MinorGC的速度比使用Serial收集器快得多。处理老年代时Throughput收集器也能使用多线程方式。这已经是JDK7u4及之后的版本的默认行为，对于之前老版本的JDK7虚拟机，通过XX:+UseParallelOldGC标志可以开启这个功能。

#### CMS收集器

CMS收集器设计的初衷是为了消除Throughput收集器和Serial收集器FullGC周期中的长时间停顿。CMS收集器在MinorGC时会暂停所有的应用线程，并以多线程的方式进行垃圾回收。然而，这其中最显著的不同是，CMS不再使用Throughput的收集算法（XX:+UseParallelGC），改用新的算法来收集新生代对象（使用XX:+UseParNewGC标志）。

CMS收集器在FullGC时不再暂停应用线程，而是使用若干个后台线程定期地对老年代空间进行扫描，及时回收其中不再使用的对象。这种算法帮助CMS成为一个低延迟的收集器：应用线程只在MinorGC以及后台线程扫描老年代时发生极其短暂的停顿。应用程序线程停顿的总时长与使用Throughput收集器比起来短得多。

#### G1垃圾收集器

G1垃圾收集器（或者垃圾优先收集器）的设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。G1收集算法将堆划分为若干个区域（Region），不过它依旧属于分代收集器。这些区域中的一部分包含新生代，新生代的垃圾收集仍然采用暂停所有应用线程的方式，将存活对象移动到老年代或者Survivor空间。同其他的收集算法一样，这些操作也利用多线程的方式完成。



1. 这四种垃圾收集算法分别采用了的不同的方法来缓解GC对应用程序的影响。

2. Serial收集器常用于仅有单CPU可用以及当其他程序会干扰GC的情况（通常是默认值）。
3. Throughput收集器在其他的虚拟机上是默认值，它能最大化应用程序的总吞吐量，但是有些操作可能遭遇较长的停顿。
4. CMS收集器能够在应用线程运行的同时并行地对老年代的垃圾进行收集。如果CPU的计算能力足以支撑后台垃圾收集线程的运行，该算法能避免应用程序发生FullGC。5.G1收集器也能在应用线程运行的同时并发地对老年代的垃圾进行收集，在某种程度上能够减少发生FullGC的风险。G1的设计理念使得它比CMS更不容易遭遇FullGC。

### 选择GC算法

### GC算法和吞吐量测试

### GC算法及响应时间测试

### CMS收集器和G1收集器之间的抉择

1. 选择Concurrent收集器时，如果堆较小，推荐使用CMS收集器。
2. G1的设计使得它能够在不同的分区（Region）处理堆，因此它的扩展性更好，比CMS更易于处理超大堆的情况。

## GC调优基础

### 调整堆的大小

堆的大小由2个参数值控制：初始值 `-Xms N`和最大值`-Xmx N`

1. JVM会根据其运行的机器，尝试估算合适的最大、最小堆的大小。

2. 除非应用程序需要比默认值更大的堆，否则在进行调优时，尽量考虑通过调整GC算法的性能目标（具体内容在下一章介绍），而非微调堆的大小来改善程序性能。

### 代空间的调整

* `-XX:NewRatio=N` 设置新生代与老年代的空间占用比率。
* `-XX:NewSize=N` 设置新生代空间的初始大小。
* `-XX:MaxNewSize=N` 设置新生代空间的最大大小。
* `-XmnN` 将`NewSize`和`MaxNewSize`设定为同一个值的快捷方法。

1. 整个堆范围内，不同代的大小划分是由新生代所占用的空间控制的。
2. 新生代的大小会随着整个堆大小的增大而增长，但这也是随着整个堆的空间比率波动变化的（依据新生代的初始值和最大值）。

### 永久代和元空间的调整

1. 永久代或元空间保存着类的元数据（并非类本体的数据）。它以分离的堆的形式存在。
2. 典型应用程序在启动后不需要载入新的类，这个区域的初始值可以依据所有类都加载后的情况设置。使用优化的初始值能够加速启动的过程。
3. 开发中的应用服务器（或者任何需要频繁重新载入类的环境）上经常能碰到由于永久代或元空间耗尽触发的FullGC，这时老的元数据会被丢弃回收。

### 控制并发

由于GC操作会暂停所有的应用程序线程，JVM为了尽量缩短停顿时间就必须尽可能地利用更多的CPU资源。JVM会在机器的每个CPU上运行一个线程，最多同时运行8个。一旦达到这个上限，JVM会调整算法，每超出5/8个CPU启动一个新的线程。


$$
ParallelGCThreads = 8 + ((N - 8) * 5 / 8)
$$

1. 几乎所有的垃圾收集算法中基本的垃圾回收线程数都依据机器上的CPU数目计算得出。
2. 多个JVM运行于同一台物理机上时，依据公式计算出的线程数可能过高，必须进行优化（减少）。

### 自适应调整

1. JVM在堆的内部如何调整新生代及老年代的百分比是由自适应调整机制控制的。
2. 通常情况下，我们应该开启自适应调整，因为垃圾回收算法依赖于调整后的代的大小来达到它停顿时间的性能目标。
3. 对于已经精细调优过的堆，关闭自适应调整能获得一定的性能提升。

## 垃圾回收工具

`-verbose:gc`或`-XX:PrintGC`这两个标志中的任意一个能创建基本GC日志

`-XX:+PrintGCDetails` 输出更详细GC日志

`XX:+PrintGCTimeStamps`或者`-XX:+PrintGCDateStamps` 判断几次GC操作之间的时间。

1. GC日志是分析GC相关问题的重要线索；我们应该开启GC日志标志（即使是在生产服务器上）。
2. 使用PrintGCDetails标志能获得更详尽的GC日志信息。
3. 使用工具能很有效地帮助我们解析和理解GC日志的内容，尤其是在对GC日志中的数据进行归纳汇总时，它们非常有帮助。
4. 使用jstat能动态地观察运行程序的垃圾回收操作。

```bash
jstat -gcutil process_id 1000    # 打印垃圾收集的信息
```



# 垃圾收集算法

## 理解Throughput收集器

* 回收新生代的垃圾
* 回收老年代的垃圾

## 理解CMS收集器

* CMS收集器会对新生代的对象进行回收（所有的应用线程都会被暂停）；
* CMS收集器会启动一个并发的线程对老年代空间的垃圾进行回收；
* 如果有必要，CMS会发起FullGC

1. CMS垃圾回收有多个操作，但是期望的操作是MinorGC和并发回收（concurrentcycle）。
2. CMS收集过程中的并发模式失效以及晋升失败的代价都非常昂贵；我们应该尽量调优CMS收集器以避免发生这些情况。
3. 默认情况下CMS收集器不会对永久代进行垃圾回收。

### 针对并发模式失效的调优

当老年代空间的占用达到某个程度（默认值为70%）时，并发回收就开始了。一个CMS后台线程开始扫描老年代空间，寻找无用的垃圾对象时，竞争就开始了：CMS收集器必须在老年代剩余的空间（30%）用尽之前，完成老年代空间的扫描及回收工作。如果并发回收在这场速度的比赛中失利，CMS收集器就会发生并发模式失效。

解决方案

* 想办法增大老年代空间，要么只移动部分的新生代对象到老年代，要么增加更多的堆空间。

* 以更高的频率运行后台回收线程。

* 使用更多的后台回收线程。

1. 给后台线程更多的运行机会
2. 调整CMS后台线程

1. 避免发生并发模式失效是提升CMS收集器处理能力、获得高性能的关键。
2. 避免并发模式失效（如果有可能的话）最简单的方法是增大堆的容量。
3. 否则，我们能进行的下一个步骤就是通过调整CMSInitiatingOccupancyFraction参数，尽早启动并发后台线程的运行。
4. 另外，调整后台线程的数目对解决这个问题也有帮助。

### CMS收集器的永久代调优

### 增量式CMS垃圾收集

java8中已经不推荐

## 理解G1垃圾收集器

G1垃圾收集器是一种工作在堆内不同分区上的并发收集器。分区（region）既可以归属于老年代，也可以归属于新生代（默认情况下，一个堆被划分成2048个分区），同一个代的分区不需要保持连续。

G1收集器的收集活动主要包括4种操作：

* 新生代垃圾收集；
* 后台收集，并发周期；
* 混合式垃圾收集；
* 以及必要时的FullGC。

1. G1垃圾收集包括多个周期（以及并发周期内的阶段）。调优良好的JVM运行G1收集器时应该只经历新生代周期、混合式周期和并发GC周期。
2. G1的并发阶段会产生少量的停顿。
3. 恰当的时候，我们需要对G1进行调优，才能避免FullGC周期发生。

### G1垃圾收集器调优

避免发生FullGC

* 通过增加总的堆空间大小或者调整老年代、新生代之间的比例来增加老年代空间的大小。
* 增加后台线程的数目（假设我们有足够的CPU资源运行这些线程）。
* 以更高的频率进行G1的后台垃圾收集活动。
* 在混合式垃圾回收周期中完成更多的垃圾收集工作。

如果无法避免FullGC

1. 调整G1垃圾收集的后台线程数
2. 调整G1垃圾收集器的运行频率
3. 调整G1收集器的混合式垃圾收集周期

1. 作为G1收集器调优的第一步，首先应该设定一个合理的停顿时间作为目标。
2. 如果使用这个设置后，还是频繁发生FullGC，并且堆的大小没有扩大的可能，这时就需要针对特定的失败采用特定的方法进行调优。　
   1. 通过InitiatingHeapOccupancyPercent标志可以调整G1收集器，更频繁地启动后台垃圾收集线程。
   2. 如果有充足的CPU资源，可以考虑调整ConcGCThreads标志，增加垃圾收集线程数。　
   3. 减小G1MixedGCCountTarget参数可以避免晋升失败。

## 高级调优

### 晋升及Survivor空间

1. 设计Survivor空间的初衷是为了让对象（尤其是已经分配的对象）在新生代停留更多的GC周期。这个设计增大了对象晋升到老年代之前被回收释放的几率。
2. 如果Survivor空间过小，对象会直接晋升到老年代，从而触发更多的老年代GC。
3. 解决这个问题的最好方法是增大堆的大小（或者至少增大新生代），让JVM来处理Survivor空间的回收。
4. 有的情况下，我们需要避免对象晋升到老年代，调整晋升阈值或者Survivor空间的大小可以避免对象晋升到老年代。

### 分配打对象

对需要分配大量大型对象的应用，TLAB空间的调整就变得必不可少（不过，通常情况下，我们更推荐在应用程序中使用小型对象的做法）。

1. G1分区的大小是2的幂，最小值为1MB。
2. 如果堆的初始大小跟最大值相差很大，这种堆会有大量的G1分区，在这种情况下，应该增大G1分区的大小。

3. 如果要分配的对象大小超过了G1收集器分区容量的一半，对于这种应用程序，我们应该增大G1分区的容量，让G1分区能更好地适配这些对象。遵循这个原则，应用程序分配对象的大小至少应是512KB（因为G1分区的最小值为1MB）。

### AggressiveHeap标志

1. AggressiveHeap是个历史悠久的调优标志，设计初衷是为了在强大的机器上运行单一JVM时调整堆的各种参数。
2. 这个标志设定的值并没有随着JVM技术的发展同步调整，因此它的有效性从长远来看是值得质疑的（虽然到目前为止，这个标志还常常被使用）。

### 全盘掌控堆空间的大小

1. 大多数的机器上堆的初始空间和最大空间的默认值计算是比较直观的。
2. 达到堆大小的临界情况时，需要考虑的因素更多，计算也更加复杂。



# 堆内存最佳实践

## 堆分析

### 堆直方图

### 堆转储

1. 了解哪些对象正在消耗内存，是了解要优化代码中哪些对象的第一步。
2. 对于识别由创建了太多某一特定类型对象所引发的内存问题，直方图这一方法快速且方便。
3. 堆转储分析是追踪内存使用的最强大的技术，不过要利用好，则需要一些耐心和努力。

### 内存溢出错误

JVM会抛出内存溢出错误（OutOfMemoryError）

* JVM没有原生内存可用；
* 永久代（在Java7和更早的版本中）或元空间（在Java8中）内存不足
* Java堆本身内存不足——对于给定的堆空间而言，应用中活跃对象太多；
* JVM执行GC耗时太多。

1. 有多种原因会导致抛出OutOfMemoryError，因此不要假设堆空间就是问题所在。
2. 对于永久代和普通的堆，内存泄漏是出现OutOfMemoryError的最常见原因；堆分析工具可以帮助我们找到泄漏的根源。

## 减少内存使用

### 减少对象大小

| 类型      | 大小                                                         |
| --------- | ------------------------------------------------------------ |
| byte      | 1                                                            |
| char      | 2                                                            |
| short     | 2                                                            |
| int       | 4                                                            |
| float     | 4                                                            |
| long      | 8                                                            |
| double    | 8                                                            |
| reference | 在32位JVM以及堆小于32GB的64位JVM上是4；在启用大堆的64位JVM上是8a |

1. 减小对象大小往往可以改进GC效率。

2. 对象大小未必总能很明显地看出来：对象会被填充到8字节的边界，对象引用的大小在32位和64位JVM上也有所不同。
3. 对象内部即使为null的实例变量也会占用空间。

### 延迟初始化

1. 只有当常用的代码路径不会初始化某个变量时，才去考虑延迟初始化该变量。
2.  一般不会在线程安全的代码上引入延迟初始化，否则会加重现有的同步成本。
3. 对于使用了线程安全对象的代码，如果要采用延迟初始化，应该使用双重检查锁。

### 不可变对象和标准划对象

1. 不可变对象为标准化（canonicalization）这种特殊的生命周期管理提供了可能性。

2. 通过标准化去掉不可变对象的冗余副本，可以极大减少应用消耗的堆内存。

### 字符串的保留

1. 如果应用中有大量字符串是一样的，那通过保留实现字符串重用收效很大。

2. 要保留很多字符串的应用可能需要调整字符串保留表的大小（除非是运行在Java7u40及更新的64位服务器JVM上）。

## 对象生命周期管理

### 对象重用

实现方式

1. 对象池
2. 局部变量

1. 对象重用通常是一种通用操作，我们并不鼓励使用它。但是这种技术可能适合初始化成本高昂，而且数量比较少的一组对象。

2. 在使用对象池还是使用线程局部变量这两种技术之间，应该有所取舍。一般而言，建设线程和可重用对象直接存在一一对应关系，则线程局部变量更容易使用。

### 弱引用、软引用与其他引用

#### 软引用

如果问题中的对象以后有很大的机会重用，可以使用软引用，但是如果该对象近期一直没有使用到（计算时也会考虑堆还有多少内存可用），垃圾收集器会回收它。软引用本质上是一个比较大的、最近最久未用（LRU）的对象池。获得较好性能的关键是确保它们会被及时清理。

#### 弱引用

当问题中的所引对象会同时被几个线程使用时，应该考虑弱引用。否则，弱引用很可能会被垃圾收集器回收：只有弱引用的对象在每个GC周期都可以回收。

#### 终结器（Finalizer）和最终引用（FinalReference）

终结器队列是一个引用队列，用于当所引对象可以被GC回收时处理Finalizer引用。

1. 非确定引用（包括软引用、弱引用、虚引用和最终引用）会改变Java对象正常的生命周期，与池或线程局部变量相比，它可以以对GC更为友好的方式实现对象重用。
2. 当应用对某个对象感兴趣，而且该对象在应用中的其他地方有强引用时，才应该使用弱引用。
3. 软引用保存可能长期存在的对象，提供了一个简单的、对GC友好的LRU缓存。
4. 非确定引用自身会消耗内存，而且会长时间抓住其他对象的内存；应该谨慎使用。



# 原生内存最佳实践

## 内存占用

在JVM使用的内存中，通常堆消耗的部分最多，但是JVM也会为内部操作分配一些内存。这类非堆内存就是原生内存。应用中也可以分配原生内存（通过JNI调用malloc()和类似方法，或者是使用NewI/O，即NIO时）。JVM使用的原生内存和堆内存的总量，就是一个应用总的内存占用（Footprint）。

### 测量内存占用

### 内存占用最小化

### 原生NIO缓冲区

开发者可以通过JNI调用来分配原生内存，但是如果NIO字节缓冲区是通过allocateDirect()方法创建的，则也会分配原生内存。从性能的角度看，原生字节缓冲区非常重要，因为它们支持原生代码和Java代码在不复制的情况下共享数据。最常见的例子是用于文件系统和套接字（socket）操作的缓冲区。把数据写入一个原生NIO缓冲区，然后再发送给通道（channel，比如文件或套接字），不需要在JVM和用于传输数据的C库之间复制数据。如果使用的是堆字节缓冲区，JVM则必须复制该缓冲区的内容。

1. JVM总的内存占用对性能影响很大，特别是当机器上的物理内存有限时。在做性能测试时，内存占用通常应该是要监控的一个方面。

2. 从调优角度看，要控制JVM的内存占用，可以限制用于直接字节缓冲区、线程栈和代码缓存的原生内存（以及堆）的使用量。

### 原生内存跟踪

`-XX:NativeMemoryTracking=off|summary|detail` 原生内存分配跟踪

`-XX:+PrintNMTStatistics` 在程序退出时打印原生内存分配信息

1. 在Java8中，原生内存跟踪（NMT）提供了JVM所使用的原生内存的详细信息。从操作系统的角度看，其中包含JVM堆（对OS而言，堆也是原生内存的一部分）。

2. 对大多数分析而言，NMT的概要模式足够了。它支持我们确定JVM提交了多少内存（以及这些内存用于干什么了）。

## 针对不同操作系统优化JVM

### 大页

#### Linux大页

```bash
grep Hugepagesize /proc/meminfo  # 内核支持哪些大页大小
echo 2200 > /proc/sys/vm/nr_hugepages  # 将这个值写到操作系统
sys.nr_hugepages     # /etc/sysctl.conf 保存值到配置文件，重启也保留
# /etc/security/limits.conf 配置用户的内存页数设置
appuser soft memlock 6513734400
appuser hard memlock 6513734400
```

#### Linux透明大页

Linux内核从2.6.32版本开始支持透明大页，这种机制不再需要上述配置。不过仍然需要为Java开启透明大页，这可以通过修改/sys/kernel/mm/transparent_hugepage/enabled来实现

1. 使用大页通常可以明显提升应用的速度。
2. 在大多数操作系统上，必须显式开启大页支持。

### 压缩oop(ordinary object pointer)

1. 压缩的oop会在最有用的时候默认开启。

2. 使用了压缩oop的31GB的堆，与稍微大一些、但因为堆太大而无法使用压缩oop的堆相比，性能通常要好一些。

# 线程与同步的性能

## 线程池与ThreadPoolExecutor

所有线程池的工作方式本质是一样的：有一个队列，任务被提交到这个队列中。（可以有不止一个队列，概念是一样的。）一定数量的线程会从该队列中取任务，然后执行。

线程池的一般行为是这样的：创建时准备好最小数目的线程，如果来了一个任务，而此时所有的线程都在忙碌，则启动一个新线程（一直到达到最大线程数），任务就可以立即执行了。否则，任务被加入等待队列，如果任务队列中已经无法加入新任务，则拒绝之。

### 设置最大线程数

### 设置最小线程数

### 线程池任务大小

### 设置ThreadPoolExecutor的大小



1. 有时对象池也是不错的选择，线程池就是情形之一：线程初始化的成本很高，线程池使得系统上的线程数容易控制。
2. 线程池必须仔细调优。盲目向池中添加新线程，在某些情况下对性能会有不利影响。
3. 在使用ThreadPoolExecutor时，选择更简单的选项通常会带来最好的、最能预见的性能。

## ForkJoinPool

1. ForkJoinPool类应该用于递归、分治算法。
2. 应该花些心思来确定，算法中的递归任务何时结束最为合适。创建太多任务会降低性能，但如果任务太少，而任务所需的执行时间又长短不一，也会降低性能。
3. Java8中使用了自动并行化的特性会用到一个公共的ForkJoinPool实例。我们可能需要根据实际情况调整这个实例的默认大小。

## 线程同步

### 同步的代价

同步代码对性能有两个方面的影响。

1. 应用在同步块上所花的时间会影响该应用的可伸缩性。
2. 获取同步锁需要一些CPU周期，所以也会影响性能。

#### 同步与可伸缩性

加速比（Speedup）可以用如下等式定义（即Amdahl定律）：

$$
Speedup = \frac{1}{(1-P)+\frac{P}{N}}
$$

P是程序并行运行部分所花的时间的比例，N是所用到的线程数（假定每个线程总有CPU可用）。所以，如果20%的代码是串行执行的（这意味着P是80%），有8个CPU可用，则可以预计存在并发的情况下加速比为3.33。

#### 锁定对象的开销

**CAS** 当存在竞争时，开销是无法预测的。CAS原语基于一种乐观的策略：线程设置某个值，执行一些代码，然后确保初始值没有被修改。如果值被修改了，那么基于CAS的代码必须再次执行这些代码。在最坏的情况下，如果有两个线程，它们都在修改CAS所保护的值，那么相互就会看到另一个线程同时也在修改这个值，就有可能会陷入无限循环。不过在实践中，两个线程不会进入这样的无限循环，但是随着竞争CAS所保护值的线程数的增加，重试次数也会增加。（如果此处的操作是只读的，那基于CAS的保护不会受竞争访问的影响。比如，不管有多少线程，它们都可以同时在同一个对象上调用AtomicLong.get()方法，而不用因竞争付出任何代价。这是使用基于CAS的设施的另一个重要优势。）

1. 线程同步有两个性能方面的代价：限制了应用的可伸缩性，以及获取锁是有开销的。
2. 同步的内存语义、基于CAS的设施和volatile关键字对性能可能会有很大的影响，特别是在有很多寄存器的大型机上。

### 避免同步

如果同步可以完全避免，那加锁的损失就不会影响应用的性能。一般的应对方式

1. 在每个线程中使用不同的对象

   使用ThreadLocal对象，在每个线程中保存一个不同的对象

2. 基于CAS的替代方案



#### volatile

考虑使用volatile变量来减少同步，进而减少其应用中的竞争。结果是，对volatile变量的同步写会非常缓慢。

比较基于CAS的设施和传统的同步时，可以使用如下指导原则：

* 如果访问的是不存在竞争的资源，那么基于CAS的保护要稍快于传统的同步（虽然完全不使用保护会更快）
* 如果访问的资源存在轻度或适度的竞争，那么基于CAS的保护要快于传统的同步（而且往往是快得多）。
* 随着所访问资源的竞争越来越剧烈，在某一时刻，传统的同步就会成为更高效的选择。在实践中，这只会出现在运行着大量线程的非常大型的机器上。
* 当被保护的值有多个读取，但不会被写入时，基于CAS的保护不会受竞争的影响。

1. 避免对同步对象的竞争，是缓解同步对性能影响的有效方式之一。
2. 线程局部变量不会受竞争之苦；对于保存实际不需要在多个线程间共享的同步对象，它们非常理想。
3. 对于确实需要共享的对象，基于CAS的工具也是避免传统的同步的方式之一。



### 伪共享

1. 对于会频繁地修改volatile变量或退出同步块的代码，伪共享对性能影响很大。
2. 伪共享很难检测。如果某个循环看上去非常耗时，可以检查该代码，看看是否与伪共享出现时的模式相匹配
3. 最好通过将数据移到局部变量中、稍后再保存来避免伪共享。作为一种替代方案，有时可以使用填充将冲突的变量移到不同的缓存行中。



## JVM线程调优

### 调节线程栈大小

使用 `-Xss=N`标志改变线程的栈大小

1. 在内存比较稀缺的机器上，可以减少线程栈大小。
2. 在32位的JVM上，可以减少线程栈大小，以便在4GB进程空间限制的条件下，稍稍增加堆可以使用的内存。

### 偏向锁

当锁被争用时，JVM（和操作系统）可以选择如何分配锁。锁可以被公平地授予，每个线程以轮转调度方式（roundrobin）获得锁。还有一种方案，即锁可以偏向于对它访问最为频繁的线程。

偏向锁背后的理论依据是，如果一个线程最近用到了某个锁，那么线程下一次执行由同一把锁保护的代码所需的数据可能仍然保存在处理器的缓存中。如果给这个线程优先获得这把锁的权利，缓存命中率可能就会增加。如果实现了这点，性能会有所改进。但是因为偏向锁也需要一些簿记信息，故有时性能可能会更糟。

特别是，使用了某个线程池的应用（包括大部分应用服务器），在偏向锁生效的情况下，性能会更糟糕。在那种编程模型下，不同的线程有同等机会访问争用的锁。对于这些类应用，使用`-XX:UseBiasedLocking`选项禁用偏向锁，会稍稍改进性能。偏向锁默认是开启的。

### 自旋锁

在处理同步锁的竞争问题时，JVM有两种选择。对于想要获得锁而陷入阻塞的线程，可以让它进入忙循环，执行一些指令，然后再次检查这个锁。也可以把这个线程放入一个队列，在锁可用时通知它（使得CPU可供其他线程使用）。

### 线程优先级



## 监控线程与锁

1. 利用系统提供的线程基本信息，可以对正在运行的线程的数目有个大致了解。

2. 就性能分析而言，当线程阻塞在某个资源或I/O上时，能够看到线程的相关细节就显得比较重要。

3. JFR使得我们可以很方便地检查引发线程阻塞的事件。

4. 利用jstack，一定程度上可以检查线程是阻塞在什么资源上。

# Java EE性能调优

## Web容器的基本性能

### 减少输出

### 减少空格

### 合并CSS和JavaScript资源

### 压缩输出

### 不要使用JSP动态编译

## 线程池

# 数据库性能最佳实践

## JDBC

### JDBC驱动程序

1. 花时间评估挑选出最适合你的应用程序的JDBC驱动程序。

2. 最合适的驱动程序往往依特定的部署环境而有所不同。对同样的应用程序，在一个部署环境中可能要使用JDBC驱动程序，在另一个部署环境中则要采用不同的JDBC驱动程序，才能有更好的性能。

3. 如果可以选择，尽量避免使用ODBC和JDBC1型的驱动程序。

### 预处理语句和语句池

使用PreparedStatement，尽量避免直接使用Statement。这二者的区别在于预处理语句让数据库有机会重用已经执行过的SQL信息。而这能够帮助节省之后运行的预处理语句的开销，提升执行效率。

#### 设置语句池

#### 语句池的管理

1. Java应用程序通常都会重复地运行同样的SQL语句。这些情况下，重用预处理语句池能极大地提升程序的性能。
2. 预处理语句必须依单个连接进行池化。大多数的JDBC驱动程序和JavaEE框架默认都提供了这一功能。
3. 预处理语句会消耗大量的堆空间。我们需要仔细调优语句池的大小，避免由于对大量大型对象池化而引起GC方面的问题。

### JDBC连接池

1. 数据库连接对象初始化的代价是昂贵的。所以在Java语言中，它们通常都会采用池技术进行管理——要么是通过JDBC驱动程序自身管理，要么在JavaEE和JPA框架中进行管理。

2. 跟其他的对象池一样，对连接池的调优也是非常重要的，我们需要确保连接池不会对垃圾收集造成负面的影响。为了达到这个目标，调优连接池，避免对数据库自身的性能产生负面影响也是非常有必要的。


### 事务

#### JDBC事务的控制

#### 事务隔离和锁

##### TRANSACTION_SERIALIZABLE　

这是最昂贵的事务模式；它要求在事务进行期间，事务涉及的所有数据都被锁定。通过主键访问数据以及通过WHERE子句访问数据都属于这种情况：使用WHERE子句时，表被锁定，避免事务进行期间有新的满足WHERE语句的记录被加入。序列化事务每次查询时看到的数据都是一样的。

##### TRANSACTION_REPEATABLE_READ　

这种模式下要求事务进行期间，所有访问的数据都被锁定。不过，其他的事务可以随时在表中插入新的行。这种模式下可能会发生“幻读”（phantomread），即事务再次执行带有WHERE子句的查询语句时，第二次可能会得到不同的数据。

##### TRANSACTION_READ_COMMITTED　

使用这种模式时，事务运行期间只有正在写入的行会被锁定。这种模式可能会发生“不可重复读”（nonrepeatableread），即在事务进行中，一个时间点读到的数据到另一个时间点再次读取时，就变得完全不同了。

##### TRANSACTION_READ_UNCOMMITTED　

这是代价最低的事务模式。事务运行期间不会施加任何锁，因此一个事务可以同时读取另一个事务写入（但尚未提交）的数据。这就是著名的“脏读”（dirtyread）；由于首次的事务可能会回滚（意味着写入操作实际并未发生），因此可能会导致一系列的问题，因为一旦发生这种情况，第二次的事务就是对非法数据进行操作。



1. 事务会从两个方面影响应用程序的性能：事务提交是非常昂贵的，与事务相关的锁机制会限制数据库的扩展性。
2. 这两个方面的效果是相互制约的：为了提交事务而等待太长时间会增大事务相关锁的持有时间。尤其是对使用严格语义的事务来说，平衡的方式是使用更多更频繁的提交来取代长时间地持有锁。
3. JDBC中为了细粒度地控制事务，可以默认使用TRANSACTION_READ_UNCOMMITTED隔离级，然后显式地按需锁定数据。

### 结果集的处理

1. 需要查询处理大量数据的应用程序应该考虑增大数据提取缓冲区的大小。
2. 我们总是面临着一个取舍，即在应用程序中载入大量的数据（直接导致垃圾收集器面临巨大的压力），还是频繁地进行数据库调用，每次获取数据集的一部分。

## JPA

### 事务处理

1. 采用UMT显式地管理事务的边界通常能提升应用程序的性能。
2. 默认的JavaEE编程模型——Servlet或者WebService通过EJB访问JPA实体——很容易支持这种模式。
3. 还有另一种替代方案，即可以按照应用程序的事务需要，将JPA的逻辑划分到不同的方法中处理。



### 对JPA的写性能进行优化

#### 尽量减少写入的字段

1. JPA应用和JDBC应用一样，受益于对数据库写操作调用的次数限制（有时还需要权衡是否持有事务锁）。
2. 语句缓存可以在JPA层面实现，也可以在JDBC层面实现。不过，我们应该首先使用JDBC层面的缓存。
3. 批量的JPA更新可以通过声明（在persistence.xml文件中）实现，也可以通过编程方式（通过调用flush()方法）实现。

 ### 对JPA的读性能进行优化

#### 读取更少的数据

#### 在查询中使用JOIN

#### 批处理和查询

1. JPA会进行多种优化，以限制（或增加）一次读取操作所返回的数据量。
2. JPA实体中，如果一个大型字段（譬如BLOB类型的字段）很少被使用，就应该延迟载入。
3. JPA实体之间存在关系时，相关的数据可以主动载入或者延迟载入，具体的选择取决于应用程序的需要。
4. 采用主动载入关系时，可以使用命名查询生成一个使用JOIN的SQL语句。应注意的是，这会影响JPA缓存，因此并不总是最好的主意（下一节会讨论它的影响）。
5. 使用命名查询读取数据比普通的查询要快很多，因为JPA实现为命名查询构造PreparedStatement更容易。

### JPA缓存

#### 默认缓存（延迟载入）

#### 缓存和主动载入(Eager Loading)

#### 联合查询和缓存

#### 避免查询

#### 调整JPA缓存的大小

1. JPA的L2缓存会自动对应用的实体进行缓存。
2. L2缓存不会对查询返回的实体进行缓存。长期来看，这种方式有利于避免查询。
3. 除非使用的JPA实现支持查询缓存，否则使用JOIN查询的效果通常会对程序的性能造成负面的效果，因为这种操作没有充分利用L2缓存。

### JPA的只读实体

* 通过合理配置JDBC或者JPA，尽可能地实现批量读取和写入。
* 优化应用使用的SQL语句。对于JDBC应用，这都是一些基本、标准的SQL命令。对JPA应用，你还需要考虑L2缓存的影响。
* 尽量减少锁的使用。如果数据不大容易发生冲突，推荐使用乐观锁（OptimisticLocking）；如果数据经常发生冲突，推荐使用悲观锁（PessimisticLocking）。
* 请务必使用预处理语句池（PreparedStatementPool）。
* 请务必合理设置连接池的大小。
* 合理地设置事务的范围：由于锁在整个事务期间都需要保持，所以在不影响应用程序扩展性的前提下，尽可能把事务的范围设置得大一些。



# Java SE API技巧

## 缓冲式I/O

1. 围绕缓冲式I/O有一些很常见的问题，这是由简单输入输出流类的默认实现引发的。
2. 文件和Socket的I/O必须正确地缓冲，对于像压缩和字符串编解码等内部操作，也是如此。

## 类加载

1. 在存在多个类加载器的复杂应用（特别是应用服务器）中，让这些类加载器支持并行，可以解决系统类加载器或者启动类加载器上的瓶颈问题。
2. 如果应用是在单线程内，则通过一个类加载器加载很多类，关掉Java7支持并行的特性可能会有好处。

## 随机数

1. Java默认的Random类的初始化的成本很高，但是一旦初始化完毕，就可以重用。
2. 在多线程代码中，应该首选ThreadLocalRandom类。
3. SecureRandom类表现出的性能也是随意的和完全随机的。在对用到这个类的代码做性能测试时，一定要认真规划。

## Java原生接口

1. JNI并不能解决性能问题。Java代码几乎总是比调用原生代码跑得快。
2. 当使用JNI时，应该限制从Java到C的调用次数；跨JNI边界的调用成本很高。
3. 使用数组或字符串的JNI代码必须固定这些对象；为避免影响垃圾收集器，应该限制固定对象的时间。



## 异常

1. 处理异常的代价未必会很高，不过还是应该在适合的时候才用。
2. 栈越深，处理异常的代价越高。
3. 对于会频繁创建的系统异常，JVM会将栈上的性能损失优化掉。
4. 关闭异常中的栈轨迹信息，有时可以提高性能，不过这个过程往往会丢失一些关键信息。



## 字符串的性能

1. 一行的字符串连接代码性能很不错。
2. 对于多行的连接操作，一定要确保使用StringBuilder。

## 日志

1. 为帮助用户找出问题，代码应该包含大量日志，但是这些日志默认都应该是关闭的。

2. 如果Logger实例的参数需要调用方法或者分配对象，那么在调用该实例之前，不要忘了测试日志级别。

## Java 集合类API

### 同步还是非同步

### 设定集合的大小

### 集合与内存使用效率

## Lambada 表达式和匿名类

1. 如果要在Lambda表达式和匿名类之间做出选择，则应该从方便编程的角度出发，因为性能上没什么差别。
2. Lambda表达式并没有实现为类，所以有个例外情况，即当类加载行为对性能影响很大时，Lambda表达式略胜一筹。

## 流和过滤器的性能

### 延迟遍历

1. 过滤器因为支持在迭代过程中结束处理，所以有很大的性能优势。
2. 即使都要处理整个数据集，一个过滤器还是要比一个迭代器稍微快些。











